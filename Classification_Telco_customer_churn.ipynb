{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Title: \n",
    "Telecommunications Customer Churn Prediction Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "This project aims to assist a telecom company in understanding their data and predicting customer churn. The company has provided access to three different datasets: the first dataset with 3000 records stored in a remote Microsoft SQL Server database, the second dataset with 2000 records stored on OneDrive, and the third dataset hosted on a GitHub repository.\n",
    "\n",
    "### 1.1. Objectives\n",
    "Understand the data: Our first objective is to provide insights into the telecom company's data, including customer demographics, services availed, and payment details. This understanding will enable the company to make informed business decisions.\n",
    "\n",
    "Find the lifetime value of each customer: By analyzing the data, we aim to identify factors that influence the rate at which customers churn. Understanding customer behavior and identifying key predictors will help the telecom company estimate the lifetime value of each customer.\n",
    "\n",
    "Predict customer churn: The primary objective is to develop a predictive model that accurately determines whether a customer is likely to churn or not. We will employ machine learning algorithms such as logistic regression, decision trees, support vector machines, random forest, etc., to build a model that effectively predicts customer churn.\n",
    "\n",
    "### 1.2. Methodology\n",
    "To achieve our objectives, we will follow the CRISP-DM framework, which consists of the following steps:\n",
    "\n",
    "Data exploration: We will thoroughly explore the datasets to gain insights into the available variables, their distributions, and relationships. This step will provide us with an initial understanding of the data and help identify any data quality issues.\n",
    "\n",
    "Missing value computations: We will identify missing values in the datasets and decide on an appropriate strategy for handling them. This may involve imputing missing values or removing data points with missing values.\n",
    "\n",
    "Feature engineering: We will perform feature engineering to transform and create new variables that can potentially improve the predictive power of our models. This step may include encoding categorical variables, scaling numerical variables, or creating interaction terms.\n",
    "\n",
    "Model development: We will utilize various machine learning algorithms such as logistic regression, decision trees, support vector machines, random forest, etc., to develop predictive models for customer churn. We will train the models on a subset of the data and evaluate their performance using appropriate metrics.\n",
    "\n",
    "Model evaluation and interpretation: We will evaluate the trained models using evaluation metrics such as accuracy, precision, recall, and F1-score. Additionally, we will interpret the models to understand the factors driving customer churn and their relative importance.\n",
    "\n",
    "Model optimization and hyperparameter tuning: We will fine-tune the models by optimizing their hyperparameters to improve their performance. This step may involve techniques like grid search or random search to find the optimal combination of hyperparameters.\n",
    "\n",
    "By following this methodology, we aim to provide valuable insights to the telecom company and develop a reliable predictive model for customer churn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyodbc in c:\\users\\user\\anaconda3\\lib\\site-packages (4.0.34)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: openpyxl in c:\\users\\user\\anaconda3\\lib\\site-packages (3.0.10)\n",
      "Requirement already satisfied: et_xmlfile in c:\\users\\user\\anaconda3\\lib\\site-packages (from openpyxl) (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pyodbc\n",
    "%pip install openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load first dataset from SQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pyodbc\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish a connection\n",
    "server = 'dap-projects-database.database.windows.net'\n",
    "database = 'dapDB'\n",
    "username = 'dataAnalyst_LP2'\n",
    "password = 'A3g@3kR$2y'\n",
    "\n",
    "# Create the connection string using the ODBC driver format\n",
    "conn_str = f'DRIVER={{ODBC Driver 17 for SQL Server}};SERVER={server};DATABASE={database};UID={username};PWD={password}'\n",
    "\n",
    "# Establish the connection using the connection string\n",
    "conn = pyodbc.connect(conn_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the database to retrieve the data\n",
    "query = 'SELECT TOP 3000 * FROM LP2_Telco_churn_first_3000'\n",
    "df_db = pd.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the dataframe\n",
    "df_db.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load second dataset (excelfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the excel file into a pandas dataframe\n",
    "df_excel = pd.read_excel('Telco-churn-second-2000.xlsx')\n",
    "\n",
    "# Display the dataframe\n",
    "df_excel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load third dataset (csv file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read third dataset\n",
    "df_csv = pd.read_csv('LP2_Telco-churn-last-2000.csv')\n",
    "\n",
    "# Display the dataframe\n",
    "df_csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions and Hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis\n",
    "\n",
    "H0: The churn rate of customers in the telecom company is not significantly influenced by various factors related to their \n",
    "demographics, services, and payment methods.\n",
    "\n",
    "H1: The churn rate of customers in the telecom company is influenced by various factors related to their demographics, services, and payment methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "1. Is there a relationship between the monthly charges and the likelihood of churn?\n",
    "2. Do customers who have internet service, specifically fiber optic, exhibit a higher churn rate compared to those with DSL or no internet service?\n",
    "3. Does the availability of online security, online backup, device protection, and tech support impact the churn rate?\n",
    "4. How does the churn rate vary based on the customers' gender?\n",
    "5. Does the presence of a partner influence the likelihood of churn?\n",
    "6. Is there a correlation between the tenure of customers and their churn rate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore individual datasets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore The Dataframe from the SQL Database(df_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Column information\n",
    "df_db.info()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_db has all 21 columns arranged as decribed in the readme file. The format for CustomerID in row 2999 is different from the rest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_db.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check unique values of each column\n",
    "for column in df_db.columns:\n",
    "    print('Column: {} - Unique Values: {}'.format(column, df_db[column].unique()))\n",
    "    print('==='*15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics of df_db to get insights into the distribution and basic characteristics of the numerical variables\n",
    "df_db.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values\n",
    "df_db.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore df_excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the dataset df_excel\n",
    "df_excel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column information\n",
    "df_excel.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# check unique values of each column\n",
    "for column in df_excel.columns:\n",
    "    print('Column: {} - Unique Values: {}'.format(column, df_excel[column].unique()))\n",
    "    print('==='*15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics of df_excel to get insights into the distribution and basic characteristics of the numerical variables\n",
    "df_excel.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values\n",
    "df_excel.isnull().sum()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "As expected, the test dataset does not have the \"Churn\" column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore df_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the dataset df_csv\n",
    "df_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column information\n",
    "df_csv.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check unique values of each column\n",
    "for column in df_csv.columns:\n",
    "    print('Column: {} - Unique Values: {}'.format(column, df_csv[column].unique()))\n",
    "    print('==='*15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics of df_csv to get insights into the distribution and basic characteristics of the numerical variables\n",
    "df_csv.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values\n",
    "df_csv.isnull().sum()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Observations:\n",
    "Dataset df_db has missing values in a number of columns. \n",
    "SeniorCitizen is supposed to be boolean type (0,1) in df_excel; but (yes, no) in df_db\n",
    "Partner is supposed to be boolean type but is object in df_excel\n",
    "Dependants is supposed to be boolean type but is object in df_excel\n",
    "PhoneService is supposed to be boolean type but is object in df_excel\n",
    "MultiplesLines is (None, True, or False) in df_db; but True or False in df_excel\n",
    "OnlineSecurity is (True/False) in df_db; but Yes/No/No Internet in df_excel\n",
    "DeviceProtection is (True/False) in df_db; but (yes/no) in df_excel\n",
    "\n",
    "TotalCharges is supposed to be float64 type but is object in df_excel"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
